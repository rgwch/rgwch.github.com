---
layout: post
title: ZFS
description: Das Zetabyte Filesystem
category: Administration
tags: [Server, admin, filesystem, Dateisystem]
---

### Überblick und Geschichte

ZFS (ursprünglich 'Zetabyte Filesystem' ist ein interessantes alternatives Dateisystem. Es wurde ursprünglich von Sun Microsystems ebtwickelt, dann mit BSD-Linux
unter einer BSD-Lizenz freigegeben und letztlich zusammen mit Sun von Oracle gekauft. Wegen dieser Wirren mit nicht zuletzt auch lizenzrechtlichen Unklarheiten, blieb
dem System der grosse Erfolg versagt. Apple hatte zumindest Lese-Support schon in OS-X 10.5 eingebaut und wollte, so munkelte man, mittelfristig HFS+ durch ZFS ersetzen. Mit dem Verkauf
 von Sun an Oracle wurden diese Pläne aber wieder begraben.

 Inzwischen entstand mit [OpenZFS](http://open-zfs.org/wiki/Main_Page) ein freier Port, dessen Lizenz eindeutig ist, und der von einer Reihe von Firmen gepusht wird.Man darf die Zukunft von ZFS somit
  jetzt als gesichert betrachten und sich näher damit befassen.


### Besondere Eigenschaften

Vieles von dem, was für ZFS "erfunden" wurde, fand Einzug in das moderne Linux-Filesystem btrfs. ZFS hat allerdings den Vorteil, stabil und ausgereift zu sein, während viele Teile
von btrfs immer noch als Beta oder experimentell gelten. Ausserdem hat ZFS den für mich ausschlaggebenden Vorteil, dass es nicht nur für Linux, sondern z.. auch für MacOS-X existiert.

### Was ist es?

ZFS ist eine Kombination aus LVM (Logical Volume Manager) und Dateisystem: Es kann also physikalische Datenträger verwalten und darauf Dateisysteme organisieren. Bei traditionellen
Systemen sind diese beiden Funktionen strikt getrennt (Ein fdisk-Programm erstellt Partitionen, ein RAID-Manager organisiert Schreib- und Lesezugriffe und ein Dateisystem erledigt die
"höheren" Funktionen wie Dateinamen und Verzeichnisse. Diese Trennung hat den Nachteil, dass das Dateisystem beispielsweise ncihts davon "weiss", welche Teile des physikalischen Datenträgers
überhaupt belegt sind. Das macht Backup- und Restorefunktionen oder das Ersetzen eines RAID-Datenträgers aufwändiger.

### Aufbau und Funktionsprinzip

Das Beste an ZFS ist, dass es im Gegensatz zu LVM und btrfs sehr leicht zu verstehen ist. Es gibt eigentlich nur zwei Befehlsgruppen: zpool und zfs.
Zpool organisiert Datenpools. Ein solcher Pool kann aus Harddisks oder Partitionen von Harddisks oder sogar Dateien bestehen. Durch einfaches Hinzufügen weiterer Datenträger
zu einem bestehenden Pool kann dessen Kapazität erhöht werden, und zwar völlig transparent: Anendungsprogramme "merken" nichts davon, wieviele Festplatten den Bereich bilden, mit
dem sie arbeiten.

In einem solchen Pool kann zfs Dateisysteme erstellen. Das ist optional. Ein Dateisystem wird automatisch beim erzeugen des Pools bereits erstellt und ist mit dem namen des Pools
ansprechbar. Weitere Dateisysteme entsprechen in etwa den Partitionen traditioneller Dateisysteme. Im Gegensatz zu solchen Partitionen sind ZFS-Dateisysteme aber flexibel: Jede
kann beliebig wachsen, so lange, bis entweder eine einzustellende Limite erreicht oder der Pool voll ist. Jedes Dateisystem kann völlig transparent Dinge wie Kompression
oder Deduplikation beinhalten.

Der vor allem bei grösseren Systemen berüchtigte Dateisystem-Check läuft bei ZFS im Hintergrund und ohne, dass man die Partition dafür aushängen muss.

Last but not least sind snapshots unter ZFS sehr einfach zu erstellen. Ein Snapshot ist eine Momentaufnahme des Dateisystems, welches in Sekundenbruchteilen erstellt wird. Einen solchen Snapshot kann man
mit "send" auf ein Backupmedium schicken, und zu jedem beliebigen späteren Zeitpunkt dorthin zurückgehen.


### Tour d'horizon

 Hier ein grundsätzlicher Einstieg (unter MacOSX; für Linux muss man die Devicenamen entsprechend anpassen. Mehr Infos zu den Optionen gibt `man zpool` und `man zfs`.

     sudo zpool create zfs1 disk1

 Dies erstellt einen pool namens zfs1 aus der Festplatte '/dev/disk1'. Wenn man stattdessen nur die zweite Partition der Platte hätte verwenden wollen, hätte man geschrieben:

     sudo zpool create zfs1 /dev/disk1s2

 Man könnte auch zwei gleich  grosse Festplatten für einen gespiegelten Pool verwenden:

     sudo zpool create zfs1 mirror disk2 disk3

Dies im Gegensatz zu:

     sudo zpool create zfs1 disk2 disk3

In diesem Fall würde zfs einen Pool erstellen, welcher die Grösse von disk2 und disk3 addiert enthält, während das erste Beispiel einen
Pool mit der Grösse des kleineren von disk2 und disk3 erstellt, welcher aber durch Spiegelung vor Datenverlust bei Diskausfall gesichert ist.

Man kann die beiden Optionen auch kombinieren:

     sudo zpool create zfs1 mirror disk2 disk3 mirror disk4 disk5

Hier haben wir einen Pool aus zwei aneinandergehängten Spiegelpaaren, also insgesamt 4 Disks mit der Kapazität von 2.

Ich glaube, damit ist das Prinzip klar und ich streife nur kurz, dass man statt Spiegeln auch Raids erstellen kann. ZFS erstellt immer
eine Variation von Raid5, die hier raidz heisst. Etwas verwirrenderweise benötigt ein raidz1 3 Disks, von denen eine ausfallen darf,
ein raidz2 4 Disks, von denen zwei ausfallen können etc. Logisch ist es aber immer ein Raid5.

### Nachträgliches Erweitern

Das Ganze wäre natürlich nicht viel wert, wenn man sich beim Einrichten schon ganz sicher sein müsste, welche Harddisk-Konfiguration man
für alle Zeiten braucht. Daher kann man jede Konfiguration nachträglich erweitern (oder auch schrumpfen).

    sudo zpool add zfs1 disk6
    sudo zpool add zfs1 mirror disk6 disk7

erweitert den Zpool um das angegebene Device resp. das angegebene Devicepaar.

    sudo zpool attach zfs1 disk6 disk7

macht aus disk6 einen mirror, wenn es noch keiner war. Wenn es schon ein mirror war, macht es einen 3-fach mirror daraus.

Das Ganze kann man noch ergänzen, indem man hot spares und schreib- oder lese-Cache-Devices zu zpools hinzufügt. Beispielsweise kann man
schnelle SSDs als Cache-Devices konfigurieren und hat dann so etwas wie Apples FusionDrive.

### Das obligate GRRR

Leider ist ZFS in aktuellen MacOS Versionen nicht mehr richtig integriert. Beim Anstöpseln eines ZFS-Devices meckert der Mac öfters, dass er das Laufwerk nicht lesen kann. Das muss man einfach ignorieren (Bloss nicht "initialisieren"). ZFS bindet das Gerät trotzdem ein. Wenn nicht, muss man mit

    sudo zpool import zfs1

nachhelfen.

Und um ein ZFS Device abzuhängen, genügt es auch nicht, es im Finder auszuwerfen. Vielmehr muss man

    sudo zpool export zfs1

eingeben.

Wie auch immer: ZFS ist sowieso nicht als Dateisystem für häufige Datenträgerwechsel gedacht, sondern eher für grosse, permanente Datensammlungen.

### Datesysteme / Filesystems

Zpool richtet immer automatisch gleich ein Root-Dateisystem in jedem Pool ein. In unserem obigen Beispiel würde das zfs1 heissen, also genauso wie der pool. Man kann diesem Dateisystem Eigenschaften verpassen, zum Beispiel:

    sudo zfs set compression=lz4 zfs1

Eine vollständige Liste aller möglichen Eigenschaften liefert `sudo zfs get all`. Man kann das Dateisystem checken mit:

    sudo zfs scrub zfs1

Das Checken und ggf. Reparieren geschieht online und im Hintergrund. Man kann also normal weiterarbeiten. Fehler sind bei ZFS seltener, als bei anderen Dateisystemen, da wichtige Informationen redundant angelegt werden (auch ohne mirror) und mit Checksummen gesichert sind. Im Fall von Mirror- oder Raidz-Pools werden allfällige trotzdem aufgetretene Fehler jeweils direkt korrigiert.

Wenn man eine feinere Aufteilung möchte, kann man ene Art Partitionen, nämlich sub-filesystems einrichten.

   sudo zfs create -o mountpoint="Volumes/hans" zfs1/hans
   sudo zfs create -o mountpoint="Volumes/peter" zfs2/peter

erstellt zwei Partitionen für Hans und Peter.
